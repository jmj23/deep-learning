{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# some imports\n",
    "import os\n",
    "from skimage.draw import polygon\n",
    "from scipy import interpolate\n",
    "import numpy as np\n",
    "np.random.seed(seed=1)\n",
    "from glob import glob\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib notebook\n",
    "from natsort import natsorted\n",
    "import keras\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# import custom functions and viewing tools\n",
    "from VisTools import multi_slice_viewer0, mask_viewer0\n",
    "from KerasModel import BlockModel, dice_coef_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#~# some parameters to set for training #~#\n",
    "# path to save best model weights\n",
    "model_version = 1\n",
    "model_weights_path = os.path.join(os.getcwd(),\n",
    "                                  'BestModelWeights_v{:02d}.h5'.format(model_version))\n",
    "# set number of subjects to be used for testing\n",
    "test_num = 10\n",
    "# set number of subjects to to be used for validation\n",
    "val_num = 10\n",
    "# whether to use data augmentation or not\n",
    "augment = True\n",
    "# how many iterations of data to train on\n",
    "numEp = 2\n",
    "# augmentation factor\n",
    "augFact = 8\n",
    "\n",
    "# set data directory\n",
    "data_dir = os.path.join('/home','johnsonj118','output')\n",
    "# find number of subjects\n",
    "numSubjs = len(glob(os.path.join(data_dir, \"input*.npy\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Randaomly select test subject indices\n",
    "# numpy is seeded so this is repeatable\n",
    "tv_inds = np.random.choice(numSubjs,test_num+val_num,replace=False)\n",
    "test_inds = tv_inds[:test_num]\n",
    "val_inds = tv_inds[test_num:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44 input files found\n",
      "44 output files found\n"
     ]
    }
   ],
   "source": [
    "input_files= natsorted(glob(os.path.join(data_dir, \"input*.npy\")))\n",
    "print('{} input files found'.format(len(input_files)))\n",
    "# split into test,train,validation\n",
    "input_files_test = np.take(input_files,test_inds)\n",
    "input_files_val = np.take(input_files,val_inds)\n",
    "input_files_train = np.delete(input_files,tv_inds)\n",
    "\n",
    "target_files= natsorted(glob(os.path.join(data_dir, \"target*.npy\")))\n",
    "print('{} output files found'.format(len(target_files)))\n",
    "# split into test and test/validation\n",
    "target_files_test = np.take(target_files,test_inds)\n",
    "target_files_val = np.take(target_files,val_inds)\n",
    "target_files_train = np.delete(target_files,tv_inds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading input data...\n",
      "Input data loaded\n"
     ]
    }
   ],
   "source": [
    "# load input data\n",
    "print('Loading input data...')\n",
    "inputs_test = np.concatenate([np.load(f) for f in input_files_test])\n",
    "inputs_val = np.concatenate([np.load(f) for f in input_files_val])\n",
    "inputs_train = np.concatenate([np.load(f) for f in input_files_test])\n",
    "# add singleton dimension for grayscale channel\n",
    "testX = inputs_test[...,np.newaxis]\n",
    "valX = inputs_val[...,np.newaxis]\n",
    "trainX = inputs_train[...,np.newaxis]\n",
    "print('Input data loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading target data...\n",
      "Target data loaded\n"
     ]
    }
   ],
   "source": [
    "# load input data\n",
    "print('Loading target data...')\n",
    "targets_test = np.concatenate([np.load(f) for f in target_files_test])\n",
    "targets_val = np.concatenate([np.load(f) for f in target_files_val])\n",
    "targets_train = np.concatenate([np.load(f) for f in target_files_test])\n",
    "# add singleton dimension for grayscale channel\n",
    "testY = targets_test[...,np.newaxis]\n",
    "valY = targets_val[...,np.newaxis]\n",
    "trainY = targets_train[...,np.newaxis]\n",
    "print('Target data loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make model\n",
    "model = BlockModel(trainX.shape,filt_num=16,numBlocks=4)\n",
    "model.compile(optimizer=Adam(), loss=dice_coef_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# setup image data generator\n",
    "if augment:\n",
    "    datagen1 = ImageDataGenerator(\n",
    "        rotation_range=15,\n",
    "        shear_range=0.5,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        fill_mode='nearest')\n",
    "    datagen2 = ImageDataGenerator(\n",
    "        rotation_range=15,\n",
    "        shear_range=0.5,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        fill_mode='nearest')\n",
    "else:\n",
    "    datagen1 = ImageDataGenerator()\n",
    "    datagen2 = ImageDataGenerator()\n",
    "# Provide the same seed and keyword arguments to the fit and flow methods\n",
    "seed = 1\n",
    "datagen1.fit(trainX, seed=seed)\n",
    "datagen2.fit(trainY, seed=seed)\n",
    "batchsize = 16\n",
    "datagen = zip( datagen1.flow( trainX, None, batchsize, seed=seed), datagen2.flow( trainY, None, batchsize, seed=seed) )\n",
    "\n",
    "# calculate number of batches\n",
    "if augment:\n",
    "    steps = np.int(trainX.shape[0]/batchsize*augFact)\n",
    "else:\n",
    "    steps = np.int(trainX.shape[0]/batchsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make callback for checkpointing\n",
    "cb_check = ModelCheckpoint(model_weights_path,monitor='val_loss',\n",
    "                                   verbose=0,save_best_only=True,\n",
    "                                   save_weights_only=True,mode='auto',period=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "model.fit_generator(datagen,\n",
    "                    steps_per_epoch=steps,\n",
    "                    epochs=numEp,\n",
    "                    callbacks=[cb_check],\n",
    "                    verbose=1,\n",
    "                    validation_data=(valX,valY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load best weights\n",
    "model.load_weights(model_weights_path)\n",
    "# evaluate on test data\n",
    "score = model.evaluate(testX,testY,verbose=0)\n",
    "print(\"Test Dice score is {:.03f}\".format(1-score))\n",
    "\n",
    "# display some results\n",
    "output = model.predict(testX,batch_size=16)\n",
    "mask_viewer0(testX[...,0],testY[...,0],output[...,0],name='Test Results')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
